# -*- coding: utf-8 -*-
"""Preprocess..ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Di5x-0shEyOxwZVS4xYkRhMisQ06rQ5y
"""

!huggingface-cli login

!pip install decord

import os, gc, cv2, glob, numpy as np, pandas as pd
import matplotlib.pyplot as plt, seaborn as sns
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, models, optimizers, callbacks
from datasets import load_dataset
from decord import VideoReader, cpu

"""#Load_data"""

from datasets import load_dataset
dataset = load_dataset("nexar-ai/nexar_collision_prediction")

dataset

"""#Preprocess"""

# مسیر cache دیتاست
base_path = "/root/.cache/huggingface/hub/datasets--nexar-ai--nexar_collision_prediction/snapshots"
snapshot_dir = [os.path.join(base_path, d) for d in os.listdir(base_path)][0]
print(" Dataset directory:", snapshot_dir)

def build_dataframe(base_dir):
    positive_videos = glob.glob(f"{base_dir}/train/positive/*.mp4")
    negative_videos = glob.glob(f"{base_dir}/train/negative/*.mp4")
    data = [{"video_path": p, "label": 1} for p in positive_videos] + \
           [{"video_path": p, "label": 0} for p in negative_videos]
    df = pd.DataFrame(data)
    print(f"Loaded {len(df)} videos (Pos:{len(positive_videos)}, Neg:{len(negative_videos)})")
    return df

df = build_dataframe(snapshot_dir)

train_df, val_df = train_test_split(
    df, test_size=0.2, stratify=df["label"], random_state=42
    )
print("Train:", len(train_df), "Val:", len(val_df))

"""#Frame"""

def load_video_frames(video_path, num_frames=32, size=(112,112), time_of_event=None):

    try:
        vr = VideoReader(video_path, ctx=cpu(0))
        total_frames = len(vr)
        fps = vr.get_avg_fps() if hasattr(vr, "get_avg_fps") else 30

        if time_of_event is not None and time_of_event > 0:
            event_frame = int(time_of_event * fps)
            start = max(event_frame - num_frames // 2, 0)
            end = min(event_frame + num_frames // 2, total_frames)
            indices = np.linspace(start, end - 1, num_frames, dtype=int)
        else:
            indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)

        frames = vr.get_batch(indices).asnumpy()
        frames = np.array([cv2.resize(f, size) for f in frames])

        frames = frames.astype("float32") / 255.0
        return frames

    except Exception as e:
        print(f" خطا در خواندن ویدیو {video_path}: {e}")
        return None

def preprocess_split(df, num_videos=100, num_frames=32):

    X, y = [], []
    num_videos = min(num_videos, len(df))
    for i in tqdm(range(num_videos), desc="Extracting frames"):
        row = df.iloc[i]
        frames = load_video_frames(
            row["video_path"],
            num_frames=num_frames,
            time_of_event=row.get("time_of_event", None)
        )
        if frames is not None:
            X.append(frames)
            y.append(row["label"])
    return np.array(X), np.array(y)

X_train, y_train = preprocess_split(train_df, num_videos=400)
X_val, y_val = preprocess_split(val_df, num_videos=100)

print("Shapes:", X_train.shape, y_train.shape)
print("Shapes:", X_val.shape, y_val.shape)

from collections import Counter
counter = Counter(y_train)
counter1 = Counter(y_val)
print(counter)
print(counter1)