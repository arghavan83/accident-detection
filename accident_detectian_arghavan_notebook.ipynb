{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def save_video_dataset(X_train, y_train, X_val, y_val, train_df, val_df, base_path='/content/drive/MyDrive/accident_detection/'):\n",
        "    \"\"\"\n",
        "    Save video frames dataset with metadata\n",
        "    \"\"\"\n",
        "    import os\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    np.save(f'{base_path}X_train.npy', X_train)\n",
        "    np.save(f'{base_path}y_train.npy', y_train)\n",
        "    np.save(f'{base_path}X_val.npy', X_val)\n",
        "    np.save(f'{base_path}y_val.npy', y_val)\n",
        "\n",
        "\n",
        "    train_df.to_pickle(f'{base_path}train_metadata.pkl')\n",
        "    val_df.to_pickle(f'{base_path}val_metadata.pkl')\n",
        "\n",
        "\n",
        "    dataset_info = {\n",
        "        'X_train_shape': X_train.shape,\n",
        "        'X_val_shape': X_val.shape,\n",
        "        'y_train_distribution': np.unique(y_train, return_counts=True),\n",
        "        'y_val_distribution': np.unique(y_val, return_counts=True),\n",
        "        'timestamp': pd.Timestamp.now()\n",
        "    }\n",
        "\n",
        "    with open(f'{base_path}dataset_info.pkl', 'wb') as f:\n",
        "        pickle.dump(dataset_info, f)\n",
        "\n",
        "    print(\" Video dataset saved successfully!\")\n",
        "    print(f\"X_train: {X_train.shape}\")\n",
        "    print(f\"X_val: {X_val.shape}\")\n",
        "    print(f\"Train metadata: {len(train_df)} videos\")\n",
        "    print(f\"Val metadata: {len(val_df)} videos\")\n",
        "\n",
        "def load_video_dataset(base_path='/content/drive/MyDrive/accident_detection/'):\n",
        "    \"\"\"\n",
        "    Load video frames dataset with metadata\n",
        "    \"\"\"\n",
        "\n",
        "    X_train = np.load(f'{base_path}X_train.npy')\n",
        "    y_train = np.load(f'{base_path}y_train.npy')\n",
        "    X_val = np.load(f'{base_path}X_val.npy')\n",
        "    y_val = np.load(f'{base_path}y_val.npy')\n",
        "\n",
        "\n",
        "    ''' with open(f'{base_path}dataset_info.pkl', 'rb') as f:\n",
        "        dataset_info = pickle.load(f)\n",
        "    '''\n",
        "    print(\"✅ Video dataset loaded successfully!\")\n",
        "    print(f\"X_train: {X_train.shape}\")\n",
        "    print(f\"X_val: {X_val.shape}\")\n",
        "    #print(f\"Train metadata: {len(train_df)} videos\")\n",
        "    #print(f\"Val metadata: {len(val_df)} videos\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val\n",
        "\n",
        "# Save your complete dataset\n",
        "#save_video_dataset(X_train, y_train, X_val, y_val, train_df, val_df)"
      ],
      "metadata": {
        "id": "70ZFElAjPKrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803cd1f4-fda7-4562-f11c-62bc46d78210"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "X_train, y_train, X_val, y_val= load_video_dataset('/content/drive/MyDrive/accident_detection/')"
      ],
      "metadata": {
        "id": "3hVmh5GOPpY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af903b35-4bc5-4f9e-cee9-b8c37bcd682e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Video dataset loaded successfully!\n",
            "X_train: (300, 16, 112, 112, 3)\n",
            "X_val: (80, 16, 112, 112, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wqOl7EtNJl2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model selectian"
      ],
      "metadata": {
        "id": "LVzMHfd9OsE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Dropout, BatchNormalization\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "def create_cnn_lstm_model(sequence_length=16, frame_height=112, frame_width=112, channels=3, num_classes=1):\n",
        "    \"\"\"\n",
        "    Create a CNN-LSTM model for accident detection using pretrained DenseNet201\n",
        "    \"\"\"\n",
        "\n",
        "    input_layer = Input(shape=(sequence_length, frame_height, frame_width, channels))\n",
        "\n",
        "\n",
        "    cnn_model = DenseNet201(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        pooling='avg',\n",
        "        input_shape=(frame_height, frame_width, channels)\n",
        "    )\n",
        "\n",
        "\n",
        "    for layer in cnn_model.layers[:-30]:\n",
        "        layer.trainable = False\n",
        "    for layer in cnn_model.layers[-30:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "\n",
        "    cnn_features = TimeDistributed(cnn_model)(input_layer)\n",
        "\n",
        "\n",
        "    cnn_features = BatchNormalization()(cnn_features)\n",
        "\n",
        "\n",
        "    lstm1 = LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(cnn_features)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "\n",
        "    lstm2 = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(lstm1)\n",
        "    lstm2 = BatchNormalization()(lstm2)\n",
        "\n",
        "\n",
        "    lstm3 = LSTM(32, dropout=0.1, recurrent_dropout=0.1)(lstm2)\n",
        "\n",
        "\n",
        "    dense1 = Dense(64, activation='relu')(lstm3)\n",
        "    dense1 = Dropout(0.3)(dense1)\n",
        "    dense1 = BatchNormalization()(dense1)\n",
        "\n",
        "\n",
        "    if num_classes == 1:\n",
        "        output_layer = Dense(1, activation='sigmoid')(dense1)\n",
        "    else:\n",
        "        output_layer = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_lstm_model(sequence_length=16, frame_height=112, frame_width=112, channels=3, num_classes=1)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7),\n",
        "    ModelCheckpoint('best_accident_model.h5', save_best_only=True, monitor='val_accuracy')\n",
        "]\n",
        "\n",
        "\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=8,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "id": "i56hE39VOrHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "outputId": "e1d7a1d1-b4ce-42ca-df0d-ed226de951ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1920\u001b[0m)       │    \u001b[38;5;34m18,321,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1920\u001b[0m)       │         \u001b[38;5;34m7,680\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,443,777</span> (74.17 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,443,777\u001b[0m (74.17 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,222,977</span> (8.48 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,222,977\u001b[0m (8.48 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,220,800</span> (65.69 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,220,800\u001b[0m (65.69 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.4528 - loss: 0.9303 - precision: 0.4958 - recall: 0.4875"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Dropout, BatchNormalization\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "drive_model_path = '/content/drive/MyDrive/accident_detection_models/'\n",
        "os.makedirs(drive_model_path, exist_ok=True)\n",
        "\n",
        "def create_cnn_lstm_model(sequence_length=16, frame_height=112, frame_width=112, channels=3, num_classes=1):\n",
        "    \"\"\"\n",
        "    Create a CNN-LSTM model for accident detection using pretrained DenseNet201\n",
        "    \"\"\"\n",
        "\n",
        "    input_layer = Input(shape=(sequence_length, frame_height, frame_width, channels))\n",
        "\n",
        "\n",
        "    cnn_model = DenseNet201(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        pooling='avg',\n",
        "        input_shape=(frame_height, frame_width, channels)\n",
        "    )\n",
        "\n",
        "\n",
        "    for layer in cnn_model.layers[:-30]:\n",
        "        layer.trainable = False\n",
        "    for layer in cnn_model.layers[-30:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "\n",
        "    cnn_features = TimeDistributed(cnn_model)(input_layer)\n",
        "\n",
        "\n",
        "    cnn_features = BatchNormalization()(cnn_features)\n",
        "\n",
        "\n",
        "    lstm1 = LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(cnn_features)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "\n",
        "    lstm2 = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(lstm1)\n",
        "    lstm2 = BatchNormalization()(lstm2)\n",
        "\n",
        "\n",
        "    lstm3 = LSTM(32, dropout=0.1, recurrent_dropout=0.1)(lstm2)\n",
        "\n",
        "\n",
        "    dense1 = Dense(64, activation='relu')(lstm3)\n",
        "    dense1 = Dropout(0.3)(dense1)\n",
        "    dense1 = BatchNormalization()(dense1)\n",
        "\n",
        "\n",
        "    if num_classes == 1:\n",
        "        output_layer = Dense(1, activation='sigmoid')(dense1)\n",
        "    else:\n",
        "        output_layer = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_lstm_model(sequence_length=16, frame_height=112, frame_width=112, channels=3, num_classes=1)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7),\n",
        "\n",
        "    ModelCheckpoint(\n",
        "        drive_model_path + 'best_accident_model.h5',\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"Models will be saved to: {drive_model_path}\")\n",
        "\n",
        "\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=8,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n",
        "\n",
        "\n",
        "final_model_path = drive_model_path + 'final_accident_model.h5'\n",
        "model.save(final_model_path)\n",
        "print(f\"Final model saved to: {final_model_path}\")\n",
        "\n",
        "\n",
        "history_path = drive_model_path + 'training_history.npy'\n",
        "np.save(history_path, history.history)\n",
        "print(f\"Training history saved to: {history_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hrtB_WCZNsdc",
        "outputId": "39c6f85e-74b6-4d12-86a7-eabd4b21f6a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1920\u001b[0m)       │    \u001b[38;5;34m18,321,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1920\u001b[0m)       │         \u001b[38;5;34m7,680\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,443,777</span> (74.17 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,443,777\u001b[0m (74.17 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,222,977</span> (8.48 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,222,977\u001b[0m (8.48 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,220,800</span> (65.69 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,220,800\u001b[0m (65.69 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models will be saved to: /content/drive/MyDrive/accident_detection_models/\n",
            "Starting training...\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796ms/step - accuracy: 0.5069 - loss: 0.8908 - precision: 0.4941 - recall: 0.4950\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51250, saving model to /content/drive/MyDrive/accident_detection_models/best_accident_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 5s/step - accuracy: 0.5065 - loss: 0.8915 - precision: 0.4941 - recall: 0.4953 - val_accuracy: 0.5125 - val_loss: 0.6903 - val_precision: 0.5306 - val_recall: 0.6190 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.5591 - loss: 0.7644 - precision: 0.5488 - recall: 0.5483\n",
            "Epoch 2: val_accuracy improved from 0.51250 to 0.56250, saving model to /content/drive/MyDrive/accident_detection_models/best_accident_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 994ms/step - accuracy: 0.5590 - loss: 0.7647 - precision: 0.5490 - recall: 0.5482 - val_accuracy: 0.5625 - val_loss: 0.6858 - val_precision: 0.5854 - val_recall: 0.5714 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738ms/step - accuracy: 0.5603 - loss: 0.7483 - precision: 0.6213 - recall: 0.5406\n",
            "Epoch 3: val_accuracy improved from 0.56250 to 0.61250, saving model to /content/drive/MyDrive/accident_detection_models/best_accident_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.5603 - loss: 0.7490 - precision: 0.6198 - recall: 0.5410 - val_accuracy: 0.6125 - val_loss: 0.6744 - val_precision: 0.6486 - val_recall: 0.5714 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - accuracy: 0.6767 - loss: 0.7284 - precision: 0.6725 - recall: 0.6924\n",
            "Epoch 4: val_accuracy improved from 0.61250 to 0.65000, saving model to /content/drive/MyDrive/accident_detection_models/best_accident_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.6757 - loss: 0.7281 - precision: 0.6716 - recall: 0.6910 - val_accuracy: 0.6500 - val_loss: 0.6587 - val_precision: 0.7188 - val_recall: 0.5476 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779ms/step - accuracy: 0.6006 - loss: 0.7146 - precision: 0.6185 - recall: 0.5675\n",
            "Epoch 5: val_accuracy improved from 0.65000 to 0.67500, saving model to /content/drive/MyDrive/accident_detection_models/best_accident_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.6014 - loss: 0.7138 - precision: 0.6191 - recall: 0.5688 - val_accuracy: 0.6750 - val_loss: 0.6483 - val_precision: 0.7105 - val_recall: 0.6429 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.6630 - loss: 0.6734 - precision: 0.6905 - recall: 0.6331\n",
            "Epoch 6: val_accuracy did not improve from 0.67500\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 866ms/step - accuracy: 0.6624 - loss: 0.6735 - precision: 0.6893 - recall: 0.6332 - val_accuracy: 0.6750 - val_loss: 0.6616 - val_precision: 0.7667 - val_recall: 0.5476 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - accuracy: 0.6116 - loss: 0.6743 - precision: 0.5764 - recall: 0.6740\n",
            "Epoch 7: val_accuracy did not improve from 0.67500\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 894ms/step - accuracy: 0.6121 - loss: 0.6746 - precision: 0.5776 - recall: 0.6741 - val_accuracy: 0.6625 - val_loss: 0.6351 - val_precision: 0.7273 - val_recall: 0.5714 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726ms/step - accuracy: 0.6896 - loss: 0.6206 - precision: 0.6752 - recall: 0.7073\n",
            "Epoch 8: val_accuracy improved from 0.67500 to 0.71250, saving model to /content/drive/MyDrive/accident_detection_models/best_accident_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6888 - loss: 0.6216 - precision: 0.6747 - recall: 0.7063 - val_accuracy: 0.7125 - val_loss: 0.6079 - val_precision: 0.7714 - val_recall: 0.6429 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - accuracy: 0.6641 - loss: 0.6375 - precision: 0.6893 - recall: 0.6649\n",
            "Epoch 9: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 889ms/step - accuracy: 0.6643 - loss: 0.6369 - precision: 0.6889 - recall: 0.6650 - val_accuracy: 0.6375 - val_loss: 0.6656 - val_precision: 0.7097 - val_recall: 0.5238 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - accuracy: 0.7436 - loss: 0.5617 - precision: 0.7279 - recall: 0.7539\n",
            "Epoch 10: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 904ms/step - accuracy: 0.7435 - loss: 0.5616 - precision: 0.7284 - recall: 0.7535 - val_accuracy: 0.5750 - val_loss: 0.7001 - val_precision: 0.6538 - val_recall: 0.4048 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - accuracy: 0.7437 - loss: 0.5269 - precision: 0.7605 - recall: 0.7122\n",
            "Epoch 11: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 885ms/step - accuracy: 0.7436 - loss: 0.5273 - precision: 0.7606 - recall: 0.7120 - val_accuracy: 0.7000 - val_loss: 0.6300 - val_precision: 0.7368 - val_recall: 0.6667 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - accuracy: 0.6916 - loss: 0.5844 - precision: 0.6642 - recall: 0.6993\n",
            "Epoch 12: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 925ms/step - accuracy: 0.6915 - loss: 0.5849 - precision: 0.6648 - recall: 0.6990 - val_accuracy: 0.6125 - val_loss: 0.6742 - val_precision: 0.6774 - val_recall: 0.5000 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - accuracy: 0.7374 - loss: 0.5661 - precision: 0.7628 - recall: 0.6997\n",
            "Epoch 13: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 900ms/step - accuracy: 0.7370 - loss: 0.5662 - precision: 0.7621 - recall: 0.6999 - val_accuracy: 0.6500 - val_loss: 0.6860 - val_precision: 0.7188 - val_recall: 0.5476 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - accuracy: 0.6977 - loss: 0.6293 - precision: 0.7054 - recall: 0.6616\n",
            "Epoch 14: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 885ms/step - accuracy: 0.6986 - loss: 0.6278 - precision: 0.7065 - recall: 0.6628 - val_accuracy: 0.6875 - val_loss: 0.6657 - val_precision: 0.7429 - val_recall: 0.6190 - learning_rate: 5.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736ms/step - accuracy: 0.7678 - loss: 0.5445 - precision: 0.8016 - recall: 0.7535\n",
            "Epoch 15: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 889ms/step - accuracy: 0.7674 - loss: 0.5442 - precision: 0.8004 - recall: 0.7534 - val_accuracy: 0.6500 - val_loss: 0.6559 - val_precision: 0.6842 - val_recall: 0.6190 - learning_rate: 5.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731ms/step - accuracy: 0.7708 - loss: 0.5005 - precision: 0.7517 - recall: 0.7892\n",
            "Epoch 16: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 874ms/step - accuracy: 0.7700 - loss: 0.5011 - precision: 0.7515 - recall: 0.7874 - val_accuracy: 0.6375 - val_loss: 0.6654 - val_precision: 0.7097 - val_recall: 0.5238 - learning_rate: 5.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step - accuracy: 0.6889 - loss: 0.5661 - precision: 0.7300 - recall: 0.6717\n",
            "Epoch 17: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 886ms/step - accuracy: 0.6899 - loss: 0.5653 - precision: 0.7300 - recall: 0.6730 - val_accuracy: 0.6250 - val_loss: 0.6688 - val_precision: 0.7000 - val_recall: 0.5000 - learning_rate: 5.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step - accuracy: 0.7323 - loss: 0.5602 - precision: 0.7059 - recall: 0.7514\n",
            "Epoch 18: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 881ms/step - accuracy: 0.7326 - loss: 0.5596 - precision: 0.7068 - recall: 0.7513 - val_accuracy: 0.6250 - val_loss: 0.6898 - val_precision: 0.7143 - val_recall: 0.4762 - learning_rate: 5.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736ms/step - accuracy: 0.7118 - loss: 0.5893 - precision: 0.7619 - recall: 0.6862\n",
            "Epoch 19: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 892ms/step - accuracy: 0.7127 - loss: 0.5873 - precision: 0.7619 - recall: 0.6871 - val_accuracy: 0.6500 - val_loss: 0.6540 - val_precision: 0.7059 - val_recall: 0.5714 - learning_rate: 2.5000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736ms/step - accuracy: 0.7666 - loss: 0.4950 - precision: 0.7578 - recall: 0.7583\n",
            "Epoch 20: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 880ms/step - accuracy: 0.7660 - loss: 0.4957 - precision: 0.7577 - recall: 0.7576 - val_accuracy: 0.6625 - val_loss: 0.6681 - val_precision: 0.7273 - val_recall: 0.5714 - learning_rate: 2.5000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - accuracy: 0.7756 - loss: 0.4787 - precision: 0.7207 - recall: 0.8015\n",
            "Epoch 21: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 913ms/step - accuracy: 0.7750 - loss: 0.4799 - precision: 0.7217 - recall: 0.7998 - val_accuracy: 0.6000 - val_loss: 0.7147 - val_precision: 0.6562 - val_recall: 0.5000 - learning_rate: 2.5000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733ms/step - accuracy: 0.7114 - loss: 0.5556 - precision: 0.7230 - recall: 0.6945\n",
            "Epoch 22: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 881ms/step - accuracy: 0.7120 - loss: 0.5551 - precision: 0.7235 - recall: 0.6956 - val_accuracy: 0.6375 - val_loss: 0.6962 - val_precision: 0.6970 - val_recall: 0.5476 - learning_rate: 2.5000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - accuracy: 0.7712 - loss: 0.4624 - precision: 0.7711 - recall: 0.7955\n",
            "Epoch 23: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 881ms/step - accuracy: 0.7704 - loss: 0.4631 - precision: 0.7703 - recall: 0.7945 - val_accuracy: 0.6375 - val_loss: 0.7098 - val_precision: 0.6757 - val_recall: 0.5952 - learning_rate: 2.5000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed!\n",
            "Final model saved to: /content/drive/MyDrive/accident_detection_models/final_accident_model.h5\n",
            "Training history saved to: /content/drive/MyDrive/accident_detection_models/training_history.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_to_drive(model, model_name=\"accident_model\"):\n",
        "    \"\"\"Manually save model to Google Drive\"\"\"\n",
        "    drive_model_path = f'/content/drive/MyDrive/accident_detection_models/{model_name}.h5'\n",
        "    model.save(drive_model_path)\n",
        "    print(f\" Model saved to: {drive_model_path}\")\n",
        "    return drive_model_path\n",
        "\n",
        "def load_model_from_drive(model_name=\"accident_model\"):\n",
        "    \"\"\"Load model from Google Drive\"\"\"\n",
        "    from tensorflow.keras.models import load_model\n",
        "    drive_model_path = f'/content/drive/MyDrive/accident_detection_models/{model_name}.h5'\n",
        "    model = load_model(drive_model_path)\n",
        "    print(f\" Model loaded from: {drive_model_path}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "save_model_to_drive(model, \"best_accident_model\")\n",
        "\n"
      ],
      "metadata": {
        "id": "394S6H5BTzgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "e1542bac-1354-4f55-b940-931109a4837f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-420863009.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Manual save example (if you want to save after training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msave_model_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_accident_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Manual load example (for future use)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "loaded_model = load_model_from_drive(\"best_accident_model1\")\n",
        "print(\"✅ Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "tTuk3yJ3TFE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247c5b50-9939-4477-d1bb-ee3536d6e738"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded from: /content/drive/MyDrive/accident_detection_models/best_accident_model1.h5\n",
            "✅ Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Dropout, BatchNormalization, GlobalAveragePooling2D, ConvLSTM2D\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "import numpy as np\n",
        "\n",
        "def create_improved_accident_model(sequence_length=16, frame_height=112, frame_width=112, channels=3):\n",
        "    \"\"\"\n",
        "    Improved CNN-LSTM model with better architecture for accident detection\n",
        "    \"\"\"\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=(sequence_length, frame_height, frame_width, channels))\n",
        "\n",
        "    # Use EfficientNetB0 - lighter and more efficient than DenseNet201\n",
        "    cnn_base = EfficientNetB0(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(frame_height, frame_width, channels)\n",
        "    )\n",
        "\n",
        "    # Freeze more layers initially (we'll unfreeze later if needed)\n",
        "    for layer in cnn_base.layers[:-50]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Create feature extractor with Global Average Pooling\n",
        "    cnn_features = TimeDistributed(cnn_base)(input_layer)\n",
        "    cnn_features = TimeDistributed(GlobalAveragePooling2D())(cnn_features)\n",
        "\n",
        "    # Better normalization and dropout\n",
        "    cnn_features = BatchNormalization()(cnn_features)\n",
        "    cnn_features = Dropout(0.3)(cnn_features)\n",
        "\n",
        "    # Improved LSTM architecture with bidirectional layers\n",
        "    lstm1 = LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3,\n",
        "                 kernel_regularizer=l2(0.01))(cnn_features)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "\n",
        "    lstm2 = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3,\n",
        "                 kernel_regularizer=l2(0.01))(lstm1)\n",
        "    lstm2 = BatchNormalization()(lstm2)\n",
        "\n",
        "    lstm3 = LSTM(64, dropout=0.2, recurrent_dropout=0.2,\n",
        "                 kernel_regularizer=l2(0.01))(lstm2)\n",
        "\n",
        "    # Enhanced classification head\n",
        "    dense1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(lstm3)\n",
        "    dense1 = BatchNormalization()(dense1)\n",
        "    dense1 = Dropout(0.4)(dense1)\n",
        "\n",
        "    dense2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(dense1)\n",
        "    dense2 = BatchNormalization()(dense2)\n",
        "    dense2 = Dropout(0.3)(dense2)\n",
        "\n",
        "    # Output layer\n",
        "    output_layer = Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Create the improved model\n",
        "model = create_improved_accident_model(sequence_length=16, frame_height=112, frame_width=112, channels=3)\n",
        "\n",
        "# Improved compilation with better optimizer and metrics\n",
        "model.compile(\n",
        "    optimizer=AdamW(learning_rate=0.001, weight_decay=0.004),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        keras.metrics.Precision(name='precision'),\n",
        "        keras.metrics.Recall(name='recall'),\n",
        "        keras.metrics.AUC(name='auc')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "npGHvO9bWxGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def create_video_augmentation():\n",
        "    \"\"\"Create data augmentation for video sequences\"\"\"\n",
        "    return tf.keras.Sequential([\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "        layers.RandomContrast(0.2),\n",
        "        # Note: We don't flip horizontally for traffic scenes (would change direction)\n",
        "    ])\n",
        "\n",
        "# Apply augmentation to training data\n",
        "augmentation_model = create_video_augmentation()\n",
        "\n",
        "def augment_video_sequence(X_batch):\n",
        "    \"\"\"Apply augmentation to a batch of video sequences\"\"\"\n",
        "    batch_size, seq_len, height, width, channels = X_batch.shape\n",
        "    X_batch = tf.reshape(X_batch, [-1, height, width, channels])\n",
        "    X_batch = augmentation_model(X_batch, training=True)\n",
        "    X_batch = tf.reshape(X_batch, [batch_size, seq_len, height, width, channels])\n",
        "    return X_batch"
      ],
      "metadata": {
        "id": "UoVRCDjYXGcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainingSchedule:\n",
        "    \"\"\"Custom training schedule with progressive unfreezing\"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.unfreeze_layers = False\n",
        "\n",
        "    def on_epoch_end(self, epoch):\n",
        "        if epoch == 10 and not self.unfreeze_layers:\n",
        "            # Unfreeze more CNN layers after 10 epochs\n",
        "            for layer in self.model.layers[1].layers:  # TimeDistributed layer\n",
        "                if hasattr(layer, 'layers'):\n",
        "                    for cnn_layer in layer.layers[-20:]:\n",
        "                        cnn_layer.trainable = True\n",
        "            self.unfreeze_layers = True\n",
        "            print(\"Unfrozen last 20 CNN layers for fine-tuning\")\n",
        "\n",
        "# Enhanced callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        monitor='val_auc',  # Monitor AUC for better overall performance\n",
        "        mode='max'\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=8,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        '/content/drive/MyDrive/accident_detection_models/best_improved_model.h5',\n",
        "        save_best_only=True,\n",
        "        monitor='val_auc',\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Handle class imbalance (if any)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "print(f\"Class weights: {class_weight_dict}\")\n",
        "\n",
        "# Custom training loop with augmentation\n",
        "def train_with_augmentation(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=8):\n",
        "    \"\"\"Train with custom augmentation\"\"\"\n",
        "    custom_schedule = CustomTrainingSchedule(model)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weight_dict,\n",
        "        shuffle=True,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n",
        "\n",
        "print(\"Starting improved training...\")\n",
        "history = train_with_augmentation(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=8)"
      ],
      "metadata": {
        "id": "m3-FZHa8XMj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Dropout, BatchNormalization\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "def create_resnet_lstm_model(sequence_length=16, frame_height=112, frame_width=112, channels=3):\n",
        "    \"\"\"\n",
        "    ResNet50 + LSTM model for accident detection\n",
        "    \"\"\"\n",
        "    # Input layer for video sequences\n",
        "    input_layer = Input(shape=(sequence_length, frame_height, frame_width, channels))\n",
        "\n",
        "    # ResNet50 - Excellent balance of performance and efficiency\n",
        "    resnet_base = ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        pooling='avg',  # Global average pooling\n",
        "        input_shape=(frame_height, frame_width, channels)\n",
        "    )\n",
        "\n",
        "    # Freeze early layers, fine-tune later layers\n",
        "    # ResNet50 has 175 layers - we'll freeze the first 100\n",
        "    for layer in resnet_base.layers[:100]:\n",
        "        layer.trainable = False\n",
        "    for layer in resnet_base.layers[100:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    print(f\"ResNet50 layers: {len(resnet_base.layers)}\")\n",
        "    print(f\"Trainable layers: {sum([layer.trainable for layer in resnet_base.layers])}\")\n",
        "\n",
        "    # Apply ResNet to each frame\n",
        "    cnn_features = TimeDistributed(resnet_base)(input_layer)\n",
        "\n",
        "    # Batch normalization after feature extraction\n",
        "    cnn_features = BatchNormalization()(cnn_features)\n",
        "\n",
        "    # LSTM layers for temporal analysis\n",
        "    lstm1 = LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(cnn_features)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "\n",
        "    lstm2 = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(lstm1)\n",
        "    lstm2 = BatchNormalization()(lstm2)\n",
        "\n",
        "    lstm3 = LSTM(32, dropout=0.1, recurrent_dropout=0.1)(lstm2)\n",
        "\n",
        "    # Classification head\n",
        "    dense1 = Dense(64, activation='relu')(lstm3)\n",
        "    dense1 = Dropout(0.3)(dense1)\n",
        "\n",
        "    output_layer = Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Create ResNet model\n",
        "model = create_resnet_lstm_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', 'precision', 'recall', 'auc']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "B5lTuBwqHVs8",
        "outputId": "6c736aa3-8c6c-44e0-e107-fa441ef3074a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "ResNet50 layers: 176\n",
            "Trainable layers: 76\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m2048\u001b[0m)       │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m2048\u001b[0m)       │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,114,624\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,114,624</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,775,297\u001b[0m (94.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,775,297</span> (94.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,636,033\u001b[0m (78.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,636,033</span> (78.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,139,264\u001b[0m (15.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,139,264</span> (15.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved callbacks for ResNet\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        monitor='val_auc',  # Monitor AUC for better performance measurement\n",
        "        mode='max'\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        '/content/drive/MyDrive/accident_detection_models/best_resnet_model.h5',\n",
        "        save_best_only=True,\n",
        "        monitor='val_auc',\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Training with ResNet\n",
        "print(\"Training ResNet50 + LSTM model...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=8,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6QeY_F-HdeR",
        "outputId": "7a469886-498f-401f-c732-69ab8a9294b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ResNet50 + LSTM model...\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.5263 - auc: 0.5361 - loss: 0.7030 - precision: 0.5628 - recall: 0.4666\n",
            "Epoch 1: val_auc improved from -inf to 0.53008, saving model to /content/drive/MyDrive/accident_detection_models/best_resnet_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 2s/step - accuracy: 0.5262 - auc: 0.5357 - loss: 0.7031 - precision: 0.5619 - recall: 0.4669 - val_accuracy: 0.5250 - val_auc: 0.5301 - val_loss: 0.6926 - val_precision: 0.5270 - val_recall: 0.9286 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - accuracy: 0.5860 - auc: 0.6236 - loss: 0.6729 - precision: 0.5845 - recall: 0.5857\n",
            "Epoch 2: val_auc improved from 0.53008 to 0.54167, saving model to /content/drive/MyDrive/accident_detection_models/best_resnet_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 946ms/step - accuracy: 0.5861 - auc: 0.6235 - loss: 0.6729 - precision: 0.5847 - recall: 0.5860 - val_accuracy: 0.5000 - val_auc: 0.5417 - val_loss: 0.6902 - val_precision: 0.5385 - val_recall: 0.3333 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809ms/step - accuracy: 0.5812 - auc: 0.6192 - loss: 0.6666 - precision: 0.6264 - recall: 0.5573\n",
            "Epoch 3: val_auc improved from 0.54167 to 0.63283, saving model to /content/drive/MyDrive/accident_detection_models/best_resnet_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 960ms/step - accuracy: 0.5805 - auc: 0.6186 - loss: 0.6668 - precision: 0.6248 - recall: 0.5568 - val_accuracy: 0.6250 - val_auc: 0.6328 - val_loss: 0.6836 - val_precision: 0.6429 - val_recall: 0.6429 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.5605 - auc: 0.6182 - loss: 0.6679 - precision: 0.5247 - recall: 0.4627\n",
            "Epoch 4: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 835ms/step - accuracy: 0.5604 - auc: 0.6181 - loss: 0.6679 - precision: 0.5260 - recall: 0.4627 - val_accuracy: 0.5750 - val_auc: 0.6244 - val_loss: 0.6798 - val_precision: 0.6111 - val_recall: 0.5238 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730ms/step - accuracy: 0.5684 - auc: 0.5925 - loss: 0.6770 - precision: 0.5174 - recall: 0.5594\n",
            "Epoch 5: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 804ms/step - accuracy: 0.5681 - auc: 0.5921 - loss: 0.6772 - precision: 0.5185 - recall: 0.5593 - val_accuracy: 0.5250 - val_auc: 0.5175 - val_loss: 0.7058 - val_precision: 0.5250 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.5817 - auc: 0.6236 - loss: 0.6716 - precision: 0.5967 - recall: 0.5907\n",
            "Epoch 6: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 780ms/step - accuracy: 0.5820 - auc: 0.6241 - loss: 0.6714 - precision: 0.5966 - recall: 0.5908 - val_accuracy: 0.5250 - val_auc: 0.5160 - val_loss: 0.7057 - val_precision: 0.6000 - val_recall: 0.2857 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - accuracy: 0.6781 - auc: 0.7177 - loss: 0.6334 - precision: 0.7059 - recall: 0.6443\n",
            "Epoch 7: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 775ms/step - accuracy: 0.6776 - auc: 0.7172 - loss: 0.6336 - precision: 0.7050 - recall: 0.6437 - val_accuracy: 0.5250 - val_auc: 0.5385 - val_loss: 0.6978 - val_precision: 0.5769 - val_recall: 0.3571 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.6815 - auc: 0.7077 - loss: 0.6332 - precision: 0.7208 - recall: 0.6443\n",
            "Epoch 8: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 790ms/step - accuracy: 0.6808 - auc: 0.7071 - loss: 0.6334 - precision: 0.7193 - recall: 0.6439 - val_accuracy: 0.5000 - val_auc: 0.5078 - val_loss: 0.7225 - val_precision: 0.7500 - val_recall: 0.0714 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.6457 - auc: 0.7137 - loss: 0.6267 - precision: 0.6226 - recall: 0.6221\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 9: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 783ms/step - accuracy: 0.6452 - auc: 0.7125 - loss: 0.6274 - precision: 0.6231 - recall: 0.6212 - val_accuracy: 0.4875 - val_auc: 0.5044 - val_loss: 0.7181 - val_precision: 0.5094 - val_recall: 0.6429 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - accuracy: 0.6251 - auc: 0.6791 - loss: 0.6423 - precision: 0.6171 - recall: 0.5928\n",
            "Epoch 10: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 774ms/step - accuracy: 0.6254 - auc: 0.6794 - loss: 0.6422 - precision: 0.6180 - recall: 0.5930 - val_accuracy: 0.5625 - val_auc: 0.5695 - val_loss: 0.6960 - val_precision: 0.6207 - val_recall: 0.4286 - learning_rate: 5.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - accuracy: 0.6792 - auc: 0.7180 - loss: 0.6216 - precision: 0.7271 - recall: 0.6350\n",
            "Epoch 11: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 782ms/step - accuracy: 0.6788 - auc: 0.7177 - loss: 0.6217 - precision: 0.7259 - recall: 0.6347 - val_accuracy: 0.5125 - val_auc: 0.5442 - val_loss: 0.7153 - val_precision: 0.5246 - val_recall: 0.7619 - learning_rate: 5.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.6778 - auc: 0.7035 - loss: 0.6319 - precision: 0.7232 - recall: 0.6354\n",
            "Epoch 12: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 787ms/step - accuracy: 0.6783 - auc: 0.7044 - loss: 0.6314 - precision: 0.7229 - recall: 0.6361 - val_accuracy: 0.5625 - val_auc: 0.5445 - val_loss: 0.7159 - val_precision: 0.5636 - val_recall: 0.7381 - learning_rate: 5.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720ms/step - accuracy: 0.6635 - auc: 0.7340 - loss: 0.6101 - precision: 0.6811 - recall: 0.6509\n",
            "Epoch 13: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 792ms/step - accuracy: 0.6639 - auc: 0.7345 - loss: 0.6098 - precision: 0.6813 - recall: 0.6512 - val_accuracy: 0.4875 - val_auc: 0.5069 - val_loss: 0.7500 - val_precision: 0.5161 - val_recall: 0.3810 - learning_rate: 5.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.6841 - auc: 0.7536 - loss: 0.5990 - precision: 0.6845 - recall: 0.6848\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 14: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 780ms/step - accuracy: 0.6832 - auc: 0.7526 - loss: 0.5996 - precision: 0.6838 - recall: 0.6837 - val_accuracy: 0.5500 - val_auc: 0.5865 - val_loss: 0.6937 - val_precision: 0.5536 - val_recall: 0.7381 - learning_rate: 5.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704ms/step - accuracy: 0.7444 - auc: 0.7892 - loss: 0.5679 - precision: 0.7940 - recall: 0.6593\n",
            "Epoch 15: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 782ms/step - accuracy: 0.7444 - auc: 0.7892 - loss: 0.5680 - precision: 0.7936 - recall: 0.6599 - val_accuracy: 0.5250 - val_auc: 0.5479 - val_loss: 0.7135 - val_precision: 0.5476 - val_recall: 0.5476 - learning_rate: 2.5000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.7541 - auc: 0.8304 - loss: 0.5500 - precision: 0.8089 - recall: 0.6835\n",
            "Epoch 16: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 781ms/step - accuracy: 0.7539 - auc: 0.8298 - loss: 0.5502 - precision: 0.8082 - recall: 0.6837 - val_accuracy: 0.5500 - val_auc: 0.5708 - val_loss: 0.7043 - val_precision: 0.5833 - val_recall: 0.5000 - learning_rate: 2.5000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.8096 - auc: 0.8915 - loss: 0.5097 - precision: 0.7979 - recall: 0.7985\n",
            "Epoch 17: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 780ms/step - accuracy: 0.8089 - auc: 0.8905 - loss: 0.5102 - precision: 0.7979 - recall: 0.7974 - val_accuracy: 0.5625 - val_auc: 0.5905 - val_loss: 0.7078 - val_precision: 0.6129 - val_recall: 0.4524 - learning_rate: 2.5000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.7657 - auc: 0.8379 - loss: 0.5328 - precision: 0.7968 - recall: 0.7318\n",
            "Epoch 18: val_auc did not improve from 0.63283\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 782ms/step - accuracy: 0.7659 - auc: 0.8379 - loss: 0.5328 - precision: 0.7966 - recall: 0.7324 - val_accuracy: 0.5125 - val_auc: 0.5385 - val_loss: 0.7530 - val_precision: 0.5455 - val_recall: 0.4286 - learning_rate: 2.5000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_densenet_progressive(sequence_length=16, frame_height=112, frame_width=112, channels=3):\n",
        "    \"\"\"\n",
        "    DenseNet with progressive unfreezing for better feature learning\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(sequence_length, frame_height, frame_width, channels))\n",
        "\n",
        "    # DenseNet201 - start completely frozen\n",
        "    densenet_base = DenseNet201(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        pooling='avg',\n",
        "        input_shape=(frame_height, frame_width, channels)\n",
        "    )\n",
        "\n",
        "    # Initially freeze all layers\n",
        "    for layer in densenet_base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    cnn_features = TimeDistributed(densenet_base)(input_layer)\n",
        "    cnn_features = BatchNormalization()(cnn_features)\n",
        "\n",
        "    # LSTM layers\n",
        "    lstm1 = LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(cnn_features)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "\n",
        "    lstm2 = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(lstm1)\n",
        "    lstm2 = BatchNormalization()(lstm2)\n",
        "\n",
        "    lstm3 = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(lstm2)\n",
        "\n",
        "    # Enhanced classification head\n",
        "    dense1 = Dense(128, activation='relu')(lstm3)\n",
        "    dense1 = BatchNormalization()(dense1)\n",
        "    dense1 = Dropout(0.4)(dense1)\n",
        "\n",
        "    dense2 = Dense(64, activation='relu')(dense1)\n",
        "    dense2 = Dropout(0.3)(dense2)\n",
        "\n",
        "    output_layer = Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Two-phase training approach\n",
        "def train_progressive(model, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Phase 1: Train with frozen backbone\n",
        "    Phase 2: Unfreeze and fine-tune last layers\n",
        "    \"\"\"\n",
        "    # Phase 1: Frozen backbone\n",
        "    print(\"=== PHASE 1: Training with frozen backbone ===\")\n",
        "    history1 = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=8,\n",
        "        epochs=15,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[\n",
        "            EarlyStopping(patience=8, restore_best_weights=True, monitor='val_accuracy'),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4)\n",
        "        ],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Phase 2: Unfreeze last 50 layers of DenseNet\n",
        "    print(\"=== PHASE 2: Fine-tuning last layers ===\")\n",
        "    densenet_layers = model.layers[1].layer.layers  # TimeDistributed -> DenseNet layers\n",
        "    for layer in densenet_layers[-50:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # Recompile with lower learning rate for fine-tuning\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.00001),  # 10x lower LR\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    history2 = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=8,\n",
        "        epochs=30,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[\n",
        "            EarlyStopping(patience=10, restore_best_weights=True, monitor='val_accuracy'),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
        "        ],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history1, history2"
      ],
      "metadata": {
        "id": "bsUHeeC7dK4F"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Dropout, BatchNormalization\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive and load your data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load your dataset\n",
        "def load_video_dataset(base_path='/content/drive/MyDrive/accident_detection/'):\n",
        "    X_train = np.load(f'{base_path}X_train.npy')\n",
        "    y_train = np.load(f'{base_path}y_train.npy')\n",
        "    X_val = np.load(f'{base_path}X_val.npy')\n",
        "    y_val = np.load(f'{base_path}y_val.npy')\n",
        "\n",
        "    print(\" Dataset loaded successfully!\")\n",
        "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val\n",
        "\n",
        "# Load your data\n",
        "X_train, y_train, X_val, y_val = load_video_dataset()\n",
        "\n",
        "def create_densenet_progressive(sequence_length=16, frame_height=112, frame_width=112, channels=3):\n",
        "    \"\"\"\n",
        "    DenseNet with progressive unfreezing for better feature learning\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(sequence_length, frame_height, frame_width, channels))\n",
        "\n",
        "    # DenseNet201 - start completely frozen\n",
        "    densenet_base = DenseNet201(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        pooling='avg',\n",
        "        input_shape=(frame_height, frame_width, channels)\n",
        "    )\n",
        "\n",
        "    # Initially freeze all layers\n",
        "    for layer in densenet_base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    print(f\" DenseNet201 loaded with {len(densenet_base.layers)} layers\")\n",
        "    print(f\" Initially frozen layers: {sum([not layer.trainable for layer in densenet_base.layers])}\")\n",
        "\n",
        "    cnn_features = TimeDistributed(densenet_base)(input_layer)\n",
        "    cnn_features = BatchNormalization()(cnn_features)\n",
        "    cnn_features = Dropout(0.2)(cnn_features)\n",
        "\n",
        "    # Enhanced LSTM layers\n",
        "    lstm1 = LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(cnn_features)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "\n",
        "    lstm2 = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(lstm1)\n",
        "    lstm2 = BatchNormalization()(lstm2)\n",
        "\n",
        "    lstm3 = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(lstm2)\n",
        "\n",
        "    # Enhanced classification head\n",
        "    dense1 = Dense(128, activation='relu')(lstm3)\n",
        "    dense1 = BatchNormalization()(dense1)\n",
        "    dense1 = Dropout(0.4)(dense1)\n",
        "\n",
        "    dense2 = Dense(64, activation='relu')(dense1)\n",
        "    dense2 = Dropout(0.3)(dense2)\n",
        "\n",
        "    output_layer = Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "def train_progressive(model, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Two-phase training approach\n",
        "    \"\"\"\n",
        "    # Callbacks for both phases\n",
        "    phase1_callbacks = [\n",
        "        EarlyStopping(patience=8, restore_best_weights=True, monitor='val_accuracy', verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1),\n",
        "        ModelCheckpoint('/content/drive/MyDrive/accident_detection_models/phase1_best.h5',\n",
        "                       save_best_only=True, monitor='val_accuracy', verbose=1)\n",
        "    ]\n",
        "\n",
        "    phase2_callbacks = [\n",
        "        EarlyStopping(patience=10, restore_best_weights=True, monitor='val_accuracy', verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
        "        ModelCheckpoint('/content/drive/MyDrive/accident_detection_models/phase2_best.h5',\n",
        "                       save_best_only=True, monitor='val_accuracy', verbose=1)\n",
        "    ]\n",
        "\n",
        "    # Phase 1: Frozen backbone\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PHASE 1: Training with frozen DenseNet backbone\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Compile for Phase 1\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall', 'auc']\n",
        "    )\n",
        "\n",
        "    history1 = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=8,\n",
        "        epochs=20,  # Increased epochs for Phase 1\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=phase1_callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Phase 2: Unfreeze last 80 layers of DenseNet for fine-tuning\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 2: Fine-tuning last 80 DenseNet layers\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Get the DenseNet model inside TimeDistributed\n",
        "    time_distributed_layer = model.layers[1]\n",
        "    densenet_layers = time_distributed_layer.layer.layers\n",
        "\n",
        "    # Unfreeze last 80 layers\n",
        "    layers_unfrozen = 0\n",
        "    for i, layer in enumerate(densenet_layers[-80:], 1):\n",
        "        layer.trainable = True\n",
        "        layers_unfrozen += 1\n",
        "\n",
        "    print(f\" Unfrozen {layers_unfrozen} layers for fine-tuning\")\n",
        "    print(f\" Trainable layers: {sum([layer.trainable for layer in densenet_layers])}/{len(densenet_layers)}\")\n",
        "\n",
        "    # Recompile with lower learning rate for fine-tuning\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.00001),  # 10x lower LR\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall', 'auc']\n",
        "    )\n",
        "\n",
        "    history2 = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=8,\n",
        "        epochs=40,  # More epochs for fine-tuning\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=phase2_callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history1, history2, model\n",
        "\n",
        "def plot_training_results(history1, history2):\n",
        "    \"\"\"Plot training results from both phases\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Combine histories\n",
        "    total_epochs = len(history1.history['accuracy']) + len(history2.history['accuracy'])\n",
        "\n",
        "    # Accuracy plot\n",
        "    axes[0, 0].plot(history1.history['accuracy'], label='Phase 1 Train', color='blue')\n",
        "    axes[0, 0].plot(history1.history['val_accuracy'], label='Phase 1 Val', color='blue', linestyle='--')\n",
        "    axes[0, 0].plot(range(len(history1.history['accuracy']), total_epochs),\n",
        "                   history2.history['accuracy'], label='Phase 2 Train', color='red')\n",
        "    axes[0, 0].plot(range(len(history1.history['val_accuracy']), total_epochs),\n",
        "                   history2.history['val_accuracy'], label='Phase 2 Val', color='red', linestyle='--')\n",
        "    axes[0, 0].axvline(x=len(history1.history['accuracy']), color='black', linestyle=':', alpha=0.7, label='Phase Switch')\n",
        "    axes[0, 0].set_title('Model Accuracy')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Loss plot\n",
        "    axes[0, 1].plot(history1.history['loss'], label='Phase 1 Train', color='blue')\n",
        "    axes[0, 1].plot(history1.history['val_loss'], label='Phase 1 Val', color='blue', linestyle='--')\n",
        "    axes[0, 1].plot(range(len(history1.history['loss']), total_epochs),\n",
        "                   history2.history['loss'], label='Phase 2 Train', color='red')\n",
        "    axes[0, 1].plot(range(len(history1.history['val_loss']), total_epochs),\n",
        "                   history2.history['val_loss'], label='Phase 2 Val', color='red', linestyle='--')\n",
        "    axes[0, 1].axvline(x=len(history1.history['loss']), color='black', linestyle=':', alpha=0.7, label='Phase Switch')\n",
        "    axes[0, 1].set_title('Model Loss')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision plot\n",
        "    axes[1, 0].plot(history1.history['precision'], label='Phase 1 Train', color='blue')\n",
        "    axes[1, 0].plot(history1.history['val_precision'], label='Phase 1 Val', color='blue', linestyle='--')\n",
        "    axes[1, 0].plot(range(len(history1.history['precision']), total_epochs),\n",
        "                   history2.history['precision'], label='Phase 2 Train', color='red')\n",
        "    axes[1, 0].plot(range(len(history1.history['val_precision']), total_epochs),\n",
        "                   history2.history['val_precision'], label='Phase 2 Val', color='red', linestyle='--')\n",
        "    axes[1, 0].axvline(x=len(history1.history['precision']), color='black', linestyle=':', alpha=0.7)\n",
        "    axes[1, 0].set_title('Model Precision')\n",
        "    axes[1, 0].set_ylabel('Precision')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Recall plot\n",
        "    axes[1, 1].plot(history1.history['recall'], label='Phase 1 Train', color='blue')\n",
        "    axes[1, 1].plot(history1.history['val_recall'], label='Phase 1 Val', color='blue', linestyle='--')\n",
        "    axes[1, 1].plot(range(len(history1.history['recall']), total_epochs),\n",
        "                   history2.history['recall'], label='Phase 2 Train', color='red')\n",
        "    axes[1, 1].plot(range(len(history1.history['val_recall']), total_epochs),\n",
        "                   history2.history['val_recall'], label='Phase 2 Val', color='red', linestyle='--')\n",
        "    axes[1, 1].axvline(x=len(history1.history['recall']), color='black', linestyle=':', alpha=0.7)\n",
        "    axes[1, 1].set_title('Model Recall')\n",
        "    axes[1, 1].set_ylabel('Recall')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main execution\n",
        "print(\"🚀 Starting Progressive Unfreezing Strategy\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create model\n",
        "model = create_densenet_progressive()\n",
        "model.summary()\n",
        "\n",
        "# Train with progressive unfreezing\n",
        "history1, history2, final_model = train_progressive(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "# Plot results\n",
        "plot_training_results(history1, history2)\n",
        "\n",
        "# Final evaluation\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "final_loss, final_accuracy, final_precision, final_recall, final_auc = final_model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\" Final Validation Accuracy: {final_accuracy:.4f}\")\n",
        "print(f\" Final Validation Precision: {final_precision:.4f}\")\n",
        "print(f\" Final Validation Recall: {final_recall:.4f}\")\n",
        "print(f\" Final Validation AUC: {final_auc:.4f}\")\n",
        "\n",
        "# Save final model\n",
        "final_model_path = '/content/drive/MyDrive/accident_detection_models/progressive_unfreezing_final.h5'\n",
        "final_model.save(final_model_path)\n",
        "print(f\" Final model saved to: {final_model_path}\")\n",
        "\n",
        "print(\"\\n Training completed! Check the plots to see if Phase 2 improved performance.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7J7dXNi3dby0",
        "outputId": "883952c3-b929-480a-cf83-a0db63ea821f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " Dataset loaded successfully!\n",
            "X_train: (300, 16, 112, 112, 3), y_train: (300,)\n",
            "X_val: (80, 16, 112, 112, 3), y_val: (80,)\n",
            "🚀 Starting Progressive Unfreezing Strategy\n",
            "============================================================\n",
            " DenseNet201 loaded with 708 layers\n",
            " Initially frozen layers: 708\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,229,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1920\u001b[0m)       │    \u001b[38;5;34m18,321,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1920\u001b[0m)       │         \u001b[38;5;34m7,680\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1920\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m2,229,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m197,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,824,129</span> (79.44 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,824,129\u001b[0m (79.44 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,497,281</span> (9.53 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,497,281\u001b[0m (9.53 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,326,848</span> (69.91 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m18,326,848\u001b[0m (69.91 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PHASE 1: Training with frozen DenseNet backbone\n",
            "============================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713ms/step - accuracy: 0.4595 - auc: 0.5891 - loss: 1.1280 - precision: 0.5002 - recall: 0.1183\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to /content/drive/MyDrive/accident_detection_models/phase1_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 5s/step - accuracy: 0.4606 - auc: 0.5891 - loss: 1.1255 - precision: 0.5005 - recall: 0.1188 - val_accuracy: 0.5000 - val_auc: 0.5119 - val_loss: 0.6946 - val_precision: 0.6000 - val_recall: 0.1429 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - accuracy: 0.5456 - auc: 0.5255 - loss: 1.0735 - precision: 0.6146 - recall: 0.2078\n",
            "Epoch 2: val_accuracy improved from 0.50000 to 0.52500, saving model to /content/drive/MyDrive/accident_detection_models/phase1_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 964ms/step - accuracy: 0.5444 - auc: 0.5242 - loss: 1.0753 - precision: 0.6117 - recall: 0.2067 - val_accuracy: 0.5250 - val_auc: 0.5407 - val_loss: 0.6942 - val_precision: 0.6429 - val_recall: 0.2143 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708ms/step - accuracy: 0.4822 - auc: 0.4950 - loss: 1.1549 - precision: 0.4175 - recall: 0.1180\n",
            "Epoch 3: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 866ms/step - accuracy: 0.4831 - auc: 0.4964 - loss: 1.1516 - precision: 0.4215 - recall: 0.1198 - val_accuracy: 0.5250 - val_auc: 0.5739 - val_loss: 0.6923 - val_precision: 0.7000 - val_recall: 0.1667 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678ms/step - accuracy: 0.4771 - auc: 0.5028 - loss: 1.0564 - precision: 0.4270 - recall: 0.1689\n",
            "Epoch 4: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 834ms/step - accuracy: 0.4785 - auc: 0.5036 - loss: 1.0559 - precision: 0.4312 - recall: 0.1702 - val_accuracy: 0.5125 - val_auc: 0.6435 - val_loss: 0.6842 - val_precision: 0.6364 - val_recall: 0.1667 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686ms/step - accuracy: 0.5024 - auc: 0.4837 - loss: 1.0679 - precision: 0.4037 - recall: 0.1631\n",
            "Epoch 5: val_accuracy improved from 0.52500 to 0.55000, saving model to /content/drive/MyDrive/accident_detection_models/phase1_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 941ms/step - accuracy: 0.5020 - auc: 0.4852 - loss: 1.0664 - precision: 0.4056 - recall: 0.1638 - val_accuracy: 0.5500 - val_auc: 0.6920 - val_loss: 0.6779 - val_precision: 0.8000 - val_recall: 0.1905 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.5158 - auc: 0.4818 - loss: 1.0794 - precision: 0.5999 - recall: 0.2072\n",
            "Epoch 6: val_accuracy improved from 0.55000 to 0.58750, saving model to /content/drive/MyDrive/accident_detection_models/phase1_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 945ms/step - accuracy: 0.5163 - auc: 0.4831 - loss: 1.0766 - precision: 0.5999 - recall: 0.2080 - val_accuracy: 0.5875 - val_auc: 0.7215 - val_loss: 0.6674 - val_precision: 0.8462 - val_recall: 0.2619 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.5480 - auc: 0.6001 - loss: 0.9100 - precision: 0.6435 - recall: 0.2699\n",
            "Epoch 7: val_accuracy did not improve from 0.58750\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 848ms/step - accuracy: 0.5482 - auc: 0.6000 - loss: 0.9098 - precision: 0.6432 - recall: 0.2702 - val_accuracy: 0.5625 - val_auc: 0.7061 - val_loss: 0.6714 - val_precision: 0.7333 - val_recall: 0.2619 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678ms/step - accuracy: 0.5864 - auc: 0.6571 - loss: 0.7631 - precision: 0.5872 - recall: 0.2647\n",
            "Epoch 8: val_accuracy did not improve from 0.58750\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 829ms/step - accuracy: 0.5859 - auc: 0.6563 - loss: 0.7649 - precision: 0.5886 - recall: 0.2661 - val_accuracy: 0.5375 - val_auc: 0.6870 - val_loss: 0.6878 - val_precision: 0.6667 - val_recall: 0.2381 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - accuracy: 0.5602 - auc: 0.6213 - loss: 0.7969 - precision: 0.5975 - recall: 0.3686\n",
            "Epoch 9: val_accuracy did not improve from 0.58750\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 847ms/step - accuracy: 0.5602 - auc: 0.6211 - loss: 0.7971 - precision: 0.5975 - recall: 0.3691 - val_accuracy: 0.5375 - val_auc: 0.6814 - val_loss: 0.6941 - val_precision: 0.6667 - val_recall: 0.2381 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683ms/step - accuracy: 0.6004 - auc: 0.6813 - loss: 0.7354 - precision: 0.6692 - recall: 0.4015\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.58750\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 839ms/step - accuracy: 0.6001 - auc: 0.6809 - loss: 0.7358 - precision: 0.6685 - recall: 0.4016 - val_accuracy: 0.5375 - val_auc: 0.6911 - val_loss: 0.7090 - val_precision: 0.6471 - val_recall: 0.2619 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687ms/step - accuracy: 0.5359 - auc: 0.6301 - loss: 0.8475 - precision: 0.6736 - recall: 0.3484\n",
            "Epoch 11: val_accuracy did not improve from 0.58750\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 831ms/step - accuracy: 0.5361 - auc: 0.6288 - loss: 0.8479 - precision: 0.6709 - recall: 0.3491 - val_accuracy: 0.5375 - val_auc: 0.6924 - val_loss: 0.7076 - val_precision: 0.6471 - val_recall: 0.2619 - learning_rate: 5.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - accuracy: 0.5394 - auc: 0.6853 - loss: 0.7538 - precision: 0.6326 - recall: 0.3229\n",
            "Epoch 12: val_accuracy did not improve from 0.58750\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 831ms/step - accuracy: 0.5405 - auc: 0.6852 - loss: 0.7532 - precision: 0.6332 - recall: 0.3240 - val_accuracy: 0.5500 - val_auc: 0.7093 - val_loss: 0.7031 - val_precision: 0.6500 - val_recall: 0.3095 - learning_rate: 5.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679ms/step - accuracy: 0.6216 - auc: 0.6863 - loss: 0.7209 - precision: 0.6399 - recall: 0.5241\n",
            "Epoch 13: val_accuracy did not improve from 0.58750\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 828ms/step - accuracy: 0.6212 - auc: 0.6859 - loss: 0.7217 - precision: 0.6400 - recall: 0.5230 - val_accuracy: 0.5500 - val_auc: 0.7121 - val_loss: 0.7028 - val_precision: 0.6500 - val_recall: 0.3095 - learning_rate: 5.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678ms/step - accuracy: 0.5616 - auc: 0.6038 - loss: 0.8060 - precision: 0.5663 - recall: 0.4152\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.58750\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 825ms/step - accuracy: 0.5618 - auc: 0.6045 - loss: 0.8055 - precision: 0.5673 - recall: 0.4154 - val_accuracy: 0.5625 - val_auc: 0.7196 - val_loss: 0.7099 - val_precision: 0.6842 - val_recall: 0.3095 - learning_rate: 5.0000e-05\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\n",
            "============================================================\n",
            "PHASE 2: Fine-tuning last 80 DenseNet layers\n",
            "============================================================\n",
            " Unfrozen 80 layers for fine-tuning\n",
            " Trainable layers: 80/708\n",
            "Epoch 1/40\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865ms/step - accuracy: 0.5128 - auc: 0.5685 - loss: 0.9703 - precision: 0.6087 - recall: 0.2766"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Dropout, BatchNormalization\n",
        "from tensorflow.keras.applications import DenseNet121  # Using smaller DenseNet\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive and load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def load_video_dataset(base_path='/content/drive/MyDrive/accident_detection/'):\n",
        "    X_train = np.load(f'{base_path}X_train.npy')\n",
        "    y_train = np.load(f'{base_path}y_train.npy')\n",
        "    X_val = np.load(f'{base_path}X_val.npy')\n",
        "    y_val = np.load(f'{base_path}y_val.npy')\n",
        "\n",
        "    print(\"✅ Dataset loaded successfully!\")\n",
        "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val\n",
        "\n",
        "# Load your data\n",
        "X_train, y_train, X_val, y_val = load_video_dataset()\n",
        "\n",
        "def create_memory_efficient_model(sequence_length=16, frame_height=112, frame_width=112, channels=3):\n",
        "    \"\"\"\n",
        "    Memory-efficient version with smaller DenseNet121 and optimized architecture\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(sequence_length, frame_height, frame_width, channels))\n",
        "\n",
        "    # Use DenseNet121 instead of DenseNet201 (smaller, less memory)\n",
        "    densenet_base = DenseNet121(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        pooling='avg',\n",
        "        input_shape=(frame_height, frame_width, channels)\n",
        "    )\n",
        "\n",
        "    # Initially freeze all layers\n",
        "    for layer in densenet_base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    print(f\"✅ DenseNet121 loaded with {len(densenet_base.layers)} layers\")\n",
        "    print(f\"✅ Initially frozen layers: {sum([not layer.trainable for layer in densenet_base.layers])}\")\n",
        "\n",
        "    cnn_features = TimeDistributed(densenet_base)(input_layer)\n",
        "    cnn_features = BatchNormalization()(cnn_features)\n",
        "    cnn_features = Dropout(0.2)(cnn_features)\n",
        "\n",
        "    # Smaller LSTM layers to save memory\n",
        "    lstm1 = LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(cnn_features)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "\n",
        "    lstm2 = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(lstm1)\n",
        "    lstm2 = BatchNormalization()(lstm2)\n",
        "\n",
        "    lstm3 = LSTM(32, dropout=0.1, recurrent_dropout=0.1)(lstm2)\n",
        "\n",
        "    # Classification head\n",
        "    dense1 = Dense(64, activation='relu')(lstm3)\n",
        "    dense1 = Dropout(0.3)(dense1)\n",
        "\n",
        "    output_layer = Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "def train_memory_safe(model, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Memory-safe training with smaller batches and gradual unfreezing\n",
        "    \"\"\"\n",
        "    # Phase 1: Only train classification head\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PHASE 1: Training classification head only\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Ensure all DenseNet layers are frozen\n",
        "    time_distributed_layer = model.layers[1]\n",
        "    densenet_layers = time_distributed_layer.layer.layers\n",
        "    for layer in densenet_layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    phase1_callbacks = [\n",
        "        EarlyStopping(patience=6, restore_best_weights=True, monitor='val_accuracy', verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "        ModelCheckpoint('/content/drive/MyDrive/accident_detection_models/phase1_safe.h5',\n",
        "                       save_best_only=True, monitor='val_accuracy')\n",
        "    ]\n",
        "\n",
        "    # Use smaller batch size for memory safety\n",
        "    history1 = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=4,  # Reduced batch size\n",
        "        epochs=15,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=phase1_callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Phase 2: Unfreeze only the last FEW layers (more conservative)\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PHASE 2: Fine-tuning last 20 DenseNet layers\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Unfreeze only last 20 layers (very conservative)\n",
        "    layers_unfrozen = 0\n",
        "    for layer in densenet_layers[-20:]:\n",
        "        layer.trainable = True\n",
        "        layers_unfrozen += 1\n",
        "\n",
        "    print(f\"✅ Unfrozen {layers_unfrozen} layers for fine-tuning\")\n",
        "\n",
        "    # Recompile with very low learning rate\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.00001),  # Very low LR\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    phase2_callbacks = [\n",
        "        EarlyStopping(patience=8, restore_best_weights=True, monitor='val_accuracy', verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
        "        ModelCheckpoint('/content/drive/MyDrive/accident_detection_models/phase2_safe.h5',\n",
        "                       save_best_only=True, monitor='val_accuracy')\n",
        "    ]\n",
        "\n",
        "    # Use even smaller batch size for Phase 2\n",
        "    history2 = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=4,  # Small batch size\n",
        "        epochs=25,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=phase2_callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history1, history2, model\n",
        "\n",
        "# Alternative: Simple Single-Phase Training (Most Reliable)\n",
        "def train_simple_effective(model, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Simple single-phase training that's guaranteed to work on T4\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SIMPLE SINGLE-PHASE TRAINING (Most Reliable)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Keep DenseNet completely frozen\n",
        "    time_distributed_layer = model.layers[1]\n",
        "    densenet_layers = time_distributed_layer.layer.layers\n",
        "    for layer in densenet_layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall', 'auc']\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=10, restore_best_weights=True, monitor='val_accuracy', verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1),\n",
        "        ModelCheckpoint('/content/drive/MyDrive/accident_detection_models/simple_best.h5',\n",
        "                       save_best_only=True, monitor='val_accuracy')\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=8,\n",
        "        epochs=50,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history, model\n",
        "\n",
        "def plot_results(history):\n",
        "    \"\"\"Plot training results\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    axes[0, 0].set_title('Model Accuracy')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Loss\n",
        "    axes[0, 1].plot(history.history['loss'], label='Train Loss')\n",
        "    axes[0, 1].plot(history.history['val_loss'], label='Val Loss')\n",
        "    axes[0, 1].set_title('Model Loss')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision\n",
        "    axes[1, 0].plot(history.history['precision'], label='Train Precision')\n",
        "    axes[1, 0].plot(history.history['val_precision'], label='Val Precision')\n",
        "    axes[1, 0].set_title('Model Precision')\n",
        "    axes[1, 0].set_ylabel('Precision')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Recall\n",
        "    axes[1, 1].plot(history.history['recall'], label='Train Recall')\n",
        "    axes[1, 1].plot(history.history['val_recall'], label='Val Recall')\n",
        "    axes[1, 1].set_title('Model Recall')\n",
        "    axes[1, 1].set_ylabel('Recall')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main execution - CHOOSE ONE APPROACH:\n",
        "\n",
        "print(\"🚀 Starting Memory-Optimized Training\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create memory-efficient model\n",
        "model = create_memory_efficient_model()\n",
        "model.summary()\n",
        "\n",
        "# OPTION 1: Try memory-safe progressive unfreezing (might still crash)\n",
        "try:\n",
        "    print(\"\\n🔄 Attempting memory-safe progressive unfreezing...\")\n",
        "    history1, history2, final_model = train_memory_safe(model, X_train, y_train, X_val, y_val)\n",
        "    print(\"✅ Progressive unfreezing completed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Progressive unfreezing failed: {e}\")\n",
        "    print(\"\\n🔄 Falling back to simple single-phase training...\")\n",
        "\n",
        "    # OPTION 2: Simple single-phase (guaranteed to work)\n",
        "    model = create_memory_efficient_model()  # Fresh model\n",
        "    history, final_model = train_simple_effective(model, X_train, y_train, X_val, y_val)\n",
        "    plot_results(history)\n",
        "\n",
        "# Final evaluation\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "final_metrics = final_model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"✅ Final Validation Accuracy: {final_metrics[1]:.4f}\")\n",
        "print(f\"✅ Final Validation Precision: {final_metrics[2]:.4f}\")\n",
        "print(f\"✅ Final Validation Recall: {final_metrics[3]:.4f}\")\n",
        "\n",
        "if len(final_metrics) > 4:\n",
        "    print(f\"✅ Final Validation AUC: {final_metrics[4]:.4f}\")\n",
        "\n",
        "# Save final model\n",
        "final_model_path = '/content/drive/MyDrive/accident_detection_models/final_t4_compatible.h5'\n",
        "final_model.save(final_model_path)\n",
        "print(f\"✅ Final model saved to: {final_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ta0y2NBJ_-hy",
        "outputId": "d79efee5-cccf-4931-e5d2-6140f1b6349e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Dataset loaded successfully!\n",
            "X_train: (300, 16, 112, 112, 3), y_train: (300,)\n",
            "X_val: (80, 16, 112, 112, 3), y_val: (80,)\n",
            "🚀 Starting Memory-Optimized Training\n",
            "============================================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "✅ DenseNet121 loaded with 428 layers\n",
            "✅ Initially frozen layers: 428\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m7,037,504\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m590,336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,696,705</span> (29.36 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,696,705\u001b[0m (29.36 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">656,769</span> (2.51 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m656,769\u001b[0m (2.51 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,039,936</span> (26.86 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,039,936\u001b[0m (26.86 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔄 Attempting memory-safe progressive unfreezing...\n",
            "============================================================\n",
            "PHASE 1: Training classification head only\n",
            "============================================================\n",
            "Epoch 1/15\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5271 - loss: 0.7119 - precision: 0.5390 - recall: 0.2861"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 5s/step - accuracy: 0.5273 - loss: 0.7118 - precision: 0.5395 - recall: 0.2865 - val_accuracy: 0.4750 - val_loss: 0.6959 - val_precision: 0.5000 - val_recall: 0.2381 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m50/75\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 3s/step - accuracy: 0.5456 - loss: 0.6964 - precision: 0.6444 - recall: 0.3295"
          ]
        }
      ]
    }
  ]
}